{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9958fc12-ba1e-4e63-89f1-702763b9ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant imports\n",
    "from pydriller import Repository\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from itertools import combinations, product\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50e6405-96ca-4470-83c1-49ef41a1a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apache Kafka repo\n",
    "path = \"./kafka\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5f7d5-aa89-4c97-a4b5-c351e2563e9a",
   "metadata": {},
   "source": [
    "### Temporal Coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c64e3af7-bf63-4d65-adfc-3ebfef8871e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all commits from repository\n",
    "commits = Repository(path).traverse_commits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bffa0228-a416-4ab1-8d6c-1973ca49d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Commits: 11903commit [02:26, 81.32commit/s]\n"
     ]
    }
   ],
   "source": [
    "files = set()\n",
    "\n",
    "for commit in tqdm(commits, desc=\"Processing Commits\", unit=\"commit\"):\n",
    "    modified_files = set([m.filename for m in commit.modified_files])\n",
    "    files.update(modified_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12533111-3995-4826-a072-cf4dddbc4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files: 7241\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of files: {len(files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c56b33-dddb-4588-bc3b-65b6506dbacf",
   "metadata": {},
   "source": [
    "First create a commit Dataframe to look up commits with following columns:\n",
    "- commit_id: int\n",
    "- timestamp: date\n",
    "- files: list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1efa569-3ef5-4e05-95e9-d7306d71c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Commits: 11903commit [02:28, 80.39commit/s] \n"
     ]
    }
   ],
   "source": [
    "def create_commit_dataframe(path, commits):\n",
    "    commit_dict = {}\n",
    "    \n",
    "    for commit in tqdm(commits, desc=\"Processing Commits\", unit=\"commit\"):\n",
    "        commit_id = commit.hash\n",
    "        commit_timestamp = commit.author_date\n",
    "        modified_files = set([m.filename for m in commit.modified_files])\n",
    "\n",
    "        commit_dict[commit_id] = {\"timestamp\": commit_timestamp,\n",
    "                                  \"files\": modified_files}\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    commit_df = pd.DataFrame.from_dict(commit_dict, orient='index').reset_index()\n",
    "    commit_df.columns = ['commit_id', 'timestamp', 'files']\n",
    "\n",
    "    return commit_df, commit_dict\n",
    "\n",
    "commit_df, commit_dict = create_commit_dataframe(path, commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fce3584-c8f4-46ed-8030-262ca950c17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>642da2f28c9bc6e373603d6d9119ce33684090f5</td>\n",
       "      <td>2011-08-01 23:41:24+00:00</td>\n",
       "      <td>{Pool.scala, encoder_helper_tests.cpp, MultiFe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbbfbaf33179f2a44ae641ccaaba1f0a8e73730f</td>\n",
       "      <td>2011-08-03 17:34:03+00:00</td>\n",
       "      <td>{.gitignore}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>665f1d0527846e1eaf6c39fd8a329dbfeb08b0c9</td>\n",
       "      <td>2011-08-05 01:36:43+00:00</td>\n",
       "      <td>{zkclient-20110412.jar}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96b8e03dd1ee23a550ca87803777b4d7bec05d5a</td>\n",
       "      <td>2011-08-07 16:29:55+00:00</td>\n",
       "      <td>{ZKEphemeralTest.scala, ZookeeperConsumerConne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7046c247dd466c90337bb39a4612115c3e41923</td>\n",
       "      <td>2011-08-07 23:56:05+00:00</td>\n",
       "      <td>{ProducerPool.scala}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  commit_id                  timestamp  \\\n",
       "0  642da2f28c9bc6e373603d6d9119ce33684090f5  2011-08-01 23:41:24+00:00   \n",
       "1  cbbfbaf33179f2a44ae641ccaaba1f0a8e73730f  2011-08-03 17:34:03+00:00   \n",
       "2  665f1d0527846e1eaf6c39fd8a329dbfeb08b0c9  2011-08-05 01:36:43+00:00   \n",
       "3  96b8e03dd1ee23a550ca87803777b4d7bec05d5a  2011-08-07 16:29:55+00:00   \n",
       "4  f7046c247dd466c90337bb39a4612115c3e41923  2011-08-07 23:56:05+00:00   \n",
       "\n",
       "                                               files  \n",
       "0  {Pool.scala, encoder_helper_tests.cpp, MultiFe...  \n",
       "1                                       {.gitignore}  \n",
       "2                            {zkclient-20110412.jar}  \n",
       "3  {ZKEphemeralTest.scala, ZookeeperConsumerConne...  \n",
       "4                               {ProducerPool.scala}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c901d17-144d-4cf9-841e-4f0865ca57d4",
   "metadata": {},
   "source": [
    "Next loop through all commits, and check which other commits in the curren time_window searching the commit-dataframe.  \n",
    "Adding/updating all file combinations of temporal coupled commits in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f42fbe5e-aed6-4bc4-b2cb-705dd69e57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_WINDOWS = [24, 48, 72, 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8478fc2d-7d40-4782-a491-e41072de90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_coupling(path, commit_df, commit_dict, time_windows, files):\n",
    "\n",
    "    result_dict = {}\n",
    "    commits = Repository(path).traverse_commits()\n",
    "\n",
    "\n",
    "    for commit in tqdm(commit_dict, desc=\"Processing Commits\", unit=\"commit\"):\n",
    "\n",
    "        commit_timestamp = commit_dict[commit][\"timestamp\"]\n",
    "        modified_files = commit_dict[commit][\"files\"]\n",
    "        modified_files = files & modified_files\n",
    "\n",
    "        for time_window in time_windows:\n",
    "            \n",
    "            time_window_end = commit_timestamp + timedelta(hours=time_window)\n",
    "\n",
    "            mask = True\n",
    "            mask &= commit_df[\"timestamp\"] >= commit_timestamp\n",
    "            mask &= commit_df[\"timestamp\"] <= time_window_end\n",
    "\n",
    "            filtered_df = commit_df[mask]\n",
    "\n",
    "            commits_in_window = set(commit_df[\"commit_id\"].unique())\n",
    "                \n",
    "            modified_files_in_window = set(filtered_df['files'].explode().unique())\n",
    "            modified_files_in_window = files & modified_files_in_window\n",
    "\n",
    "            result_dict = add_coupled_files_to_dict(result_dict, modified_files, modified_files_in_window, time_window, files)\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "def add_coupled_files_to_dict(dictionary, file_set_1, file_set_2, time_window, files):\n",
    "\n",
    "    file_combinations = [(file1, file2) for file1, file2 in product(file_set_1, file_set_2) if file1 != file2]\n",
    "\n",
    "    for file1, file2 in file_combinations:\n",
    "        combination = sorted([file1, file2])\n",
    "        key = f\"{combination[0]} - {combination[1]}\"\n",
    "\n",
    "        if key not in dictionary:\n",
    "            dictionary[key] = {\n",
    "                \"files\": [file1, file2],\n",
    "                \"time_windows\": {24: 0, 48: 0, 72: 0, 168: 0}\n",
    "            }\n",
    "\n",
    "        dictionary[key][\"time_windows\"][time_window] = dictionary[key][\"time_windows\"].get(time_window, 0) + 1\n",
    "   \n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0a3a3e6-1092-461f-9aa5-2c33ee49fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Commits: 100%|█████████████| 11903/11903 [23:02<00:00,  8.61commit/s]\n"
     ]
    }
   ],
   "source": [
    "temporal_coupling_result = temporal_coupling(path, commit_df, commit_dict, TIME_WINDOWS, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2477aba-ce4d-4e49-bacf-17ea870eac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_temporal_coupling_to_json(dictionary, file_name):\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for key in tqdm(dictionary, desc=\"Processing Coupled Files\", unit=\"file-pair\"):\n",
    "\n",
    "        file_pair = dictionary[key][\"files\"]\n",
    "        joint_commits_24 = dictionary[key][\"time_windows\"][24]\n",
    "        joint_commits_48 = dictionary[key][\"time_windows\"][48]\n",
    "        joint_commits_72 = dictionary[key][\"time_windows\"][72]\n",
    "        joint_commits_168 = dictionary[key][\"time_windows\"][168]\n",
    "\n",
    "\n",
    "        # Create a dictionary for the current pair\n",
    "        current_dict = {\n",
    "            \"file_pair\": file_pair,\n",
    "            \"coupled_commits\": [\n",
    "                {\n",
    "                    \"time_window\": 24,\n",
    "                    \"commit_count\": joint_commits_24\n",
    "                },\n",
    "                {\n",
    "                    \"time_window\": 48,\n",
    "                    \"commit_count\": joint_commits_48\n",
    "                },\n",
    "                {\n",
    "                    \"time_window\": 72,\n",
    "                    \"commit_count\": joint_commits_72\n",
    "                },\n",
    "                {\n",
    "                    \"time_window\": 168,\n",
    "                    \"commit_count\": joint_commits_168\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the result list\n",
    "        result_list.append(current_dict)\n",
    "\n",
    "    # Save the list of dictionaries to a JSON file\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(result_list, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f71225b9-3dcb-4086-8d99-cb7149d423e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Coupled Files: 100%|█| 4705414/4705414 [00:18<00:00, 252753.67file-pa\n"
     ]
    }
   ],
   "source": [
    "store_temporal_coupling_to_json(temporal_coupling_result, \"temporal_coupling.JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fad0ff5-ce06-44b9-b53c-0a9a5190f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_entries_with_largest_temporal_coupling(comb_dict, time_window, top_n):\n",
    "    top_entries = sorted(comb_dict.items(), key=lambda x: x[1][\"time_windows\"][time_window], reverse=True)[:top_n]\n",
    "    \n",
    "    return top_entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210207a-3132-4353-92f7-3f3996fcea85",
   "metadata": {},
   "source": [
    "10 Strongest temporal coupled files in 24 h window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f7401d2-866c-45db-9ba7-2202ab983e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KafkaApis.scala - ReplicaManager.scala',\n",
       "  {'files': ['KafkaApis.scala', 'ReplicaManager.scala'],\n",
       "   'time_windows': {24: 397, 48: 483, 72: 521, 168: 675}}),\n",
       " ('StreamThread.java - StreamThreadTest.java',\n",
       "  {'files': ['StreamThread.java', 'StreamThreadTest.java'],\n",
       "   'time_windows': {24: 370, 48: 388, 72: 402, 168: 448}}),\n",
       " ('KafkaApis.scala - RequestResponseTest.java',\n",
       "  {'files': ['KafkaApis.scala', 'RequestResponseTest.java'],\n",
       "   'time_windows': {24: 369, 48: 411, 72: 433, 168: 508}}),\n",
       " ('Partition.scala - ReplicaManager.scala',\n",
       "  {'files': ['Partition.scala', 'ReplicaManager.scala'],\n",
       "   'time_windows': {24: 353, 48: 375, 72: 393, 168: 439}}),\n",
       " ('KafkaApis.scala - TestUtils.scala',\n",
       "  {'files': ['TestUtils.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 347, 48: 420, 72: 473, 168: 641}}),\n",
       " ('Log.scala - LogTest.scala',\n",
       "  {'files': ['LogTest.scala', 'Log.scala'],\n",
       "   'time_windows': {24: 341, 48: 357, 72: 370, 168: 410}}),\n",
       " ('KafkaApis.scala - KafkaServer.scala',\n",
       "  {'files': ['KafkaServer.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 332, 48: 396, 72: 433, 168: 573}}),\n",
       " ('build.gradle - dependencies.gradle',\n",
       "  {'files': ['build.gradle', 'dependencies.gradle'],\n",
       "   'time_windows': {24: 330, 48: 379, 72: 409, 168: 529}}),\n",
       " ('KafkaApis.scala - KafkaApisTest.scala',\n",
       "  {'files': ['KafkaApis.scala', 'KafkaApisTest.scala'],\n",
       "   'time_windows': {24: 319, 48: 345, 72: 366, 168: 418}}),\n",
       " ('ReplicaManager.scala - ReplicaManagerTest.scala',\n",
       "  {'files': ['ReplicaManager.scala', 'ReplicaManagerTest.scala'],\n",
       "   'time_windows': {24: 304, 48: 321, 72: 332, 168: 389}})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_entries_with_largest_temporal_coupling(temporal_coupling_result, 24, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde6ae6-9a02-4418-bebb-0eb67b69a39f",
   "metadata": {},
   "source": [
    "10 Strongest temporal coupled files in 48 h window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c411274-8b55-4ac2-9bfa-b114bc4f8023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KafkaApis.scala - ReplicaManager.scala',\n",
       "  {'files': ['KafkaApis.scala', 'ReplicaManager.scala'],\n",
       "   'time_windows': {24: 397, 48: 483, 72: 521, 168: 675}}),\n",
       " ('KafkaApis.scala - TestUtils.scala',\n",
       "  {'files': ['TestUtils.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 347, 48: 420, 72: 473, 168: 641}}),\n",
       " ('KafkaApis.scala - RequestResponseTest.java',\n",
       "  {'files': ['KafkaApis.scala', 'RequestResponseTest.java'],\n",
       "   'time_windows': {24: 369, 48: 411, 72: 433, 168: 508}}),\n",
       " ('KafkaApis.scala - KafkaServer.scala',\n",
       "  {'files': ['KafkaServer.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 332, 48: 396, 72: 433, 168: 573}}),\n",
       " ('StreamThread.java - StreamThreadTest.java',\n",
       "  {'files': ['StreamThread.java', 'StreamThreadTest.java'],\n",
       "   'time_windows': {24: 370, 48: 388, 72: 402, 168: 448}}),\n",
       " ('build.gradle - dependencies.gradle',\n",
       "  {'files': ['build.gradle', 'dependencies.gradle'],\n",
       "   'time_windows': {24: 330, 48: 379, 72: 409, 168: 529}}),\n",
       " ('Partition.scala - ReplicaManager.scala',\n",
       "  {'files': ['Partition.scala', 'ReplicaManager.scala'],\n",
       "   'time_windows': {24: 353, 48: 375, 72: 393, 168: 439}}),\n",
       " ('KafkaApis.scala - KafkaConfig.scala',\n",
       "  {'files': ['KafkaConfig.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 282, 48: 363, 72: 418, 168: 589}}),\n",
       " ('Log.scala - LogTest.scala',\n",
       "  {'files': ['LogTest.scala', 'Log.scala'],\n",
       "   'time_windows': {24: 341, 48: 357, 72: 370, 168: 410}}),\n",
       " ('KafkaApis.scala - KafkaApisTest.scala',\n",
       "  {'files': ['KafkaApis.scala', 'KafkaApisTest.scala'],\n",
       "   'time_windows': {24: 319, 48: 345, 72: 366, 168: 418}})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_entries_with_largest_temporal_coupling(temporal_coupling_result, 48, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e2774-2907-4a77-9a50-489c2735ca03",
   "metadata": {},
   "source": [
    "10 Strongest temporal coupled files in 72 h window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba33fccb-3641-4283-8a32-05721bc87877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KafkaApis.scala - ReplicaManager.scala',\n",
       "  {'files': ['KafkaApis.scala', 'ReplicaManager.scala'],\n",
       "   'time_windows': {24: 397, 48: 483, 72: 521, 168: 675}}),\n",
       " ('KafkaApis.scala - TestUtils.scala',\n",
       "  {'files': ['TestUtils.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 347, 48: 420, 72: 473, 168: 641}}),\n",
       " ('KafkaApis.scala - KafkaServer.scala',\n",
       "  {'files': ['KafkaServer.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 332, 48: 396, 72: 433, 168: 573}}),\n",
       " ('KafkaApis.scala - RequestResponseTest.java',\n",
       "  {'files': ['KafkaApis.scala', 'RequestResponseTest.java'],\n",
       "   'time_windows': {24: 369, 48: 411, 72: 433, 168: 508}}),\n",
       " ('KafkaApis.scala - build.gradle',\n",
       "  {'files': ['KafkaApis.scala', 'build.gradle'],\n",
       "   'time_windows': {24: 233, 48: 344, 72: 427, 168: 672}}),\n",
       " ('KafkaApis.scala - KafkaConfig.scala',\n",
       "  {'files': ['KafkaConfig.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 282, 48: 363, 72: 418, 168: 589}}),\n",
       " ('build.gradle - dependencies.gradle',\n",
       "  {'files': ['build.gradle', 'dependencies.gradle'],\n",
       "   'time_windows': {24: 330, 48: 379, 72: 409, 168: 529}}),\n",
       " ('StreamThread.java - StreamThreadTest.java',\n",
       "  {'files': ['StreamThread.java', 'StreamThreadTest.java'],\n",
       "   'time_windows': {24: 370, 48: 388, 72: 402, 168: 448}}),\n",
       " ('KafkaApis.scala - Log.scala',\n",
       "  {'files': ['Log.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 281, 48: 342, 72: 394, 168: 543}}),\n",
       " ('Partition.scala - ReplicaManager.scala',\n",
       "  {'files': ['Partition.scala', 'ReplicaManager.scala'],\n",
       "   'time_windows': {24: 353, 48: 375, 72: 393, 168: 439}})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_entries_with_largest_temporal_coupling(temporal_coupling_result, 72, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9509d-db8c-45de-8058-15e7af355b93",
   "metadata": {},
   "source": [
    "10 Strongest temporal coupled files in 168 h window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d48945d-f9f6-4fca-8cfc-03a65fe81991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KafkaApis.scala - ReplicaManager.scala',\n",
       "  {'files': ['KafkaApis.scala', 'ReplicaManager.scala'],\n",
       "   'time_windows': {24: 397, 48: 483, 72: 521, 168: 675}}),\n",
       " ('KafkaApis.scala - build.gradle',\n",
       "  {'files': ['KafkaApis.scala', 'build.gradle'],\n",
       "   'time_windows': {24: 233, 48: 344, 72: 427, 168: 672}}),\n",
       " ('KafkaApis.scala - TestUtils.scala',\n",
       "  {'files': ['TestUtils.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 347, 48: 420, 72: 473, 168: 641}}),\n",
       " ('KafkaApis.scala - KafkaConfig.scala',\n",
       "  {'files': ['KafkaConfig.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 282, 48: 363, 72: 418, 168: 589}}),\n",
       " ('KafkaApis.scala - KafkaServer.scala',\n",
       "  {'files': ['KafkaServer.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 332, 48: 396, 72: 433, 168: 573}}),\n",
       " ('KafkaApis.scala - Log.scala',\n",
       "  {'files': ['Log.scala', 'KafkaApis.scala'],\n",
       "   'time_windows': {24: 281, 48: 342, 72: 394, 168: 543}}),\n",
       " ('build.gradle - dependencies.gradle',\n",
       "  {'files': ['build.gradle', 'dependencies.gradle'],\n",
       "   'time_windows': {24: 330, 48: 379, 72: 409, 168: 529}}),\n",
       " ('KafkaConfig.scala - build.gradle',\n",
       "  {'files': ['build.gradle', 'KafkaConfig.scala'],\n",
       "   'time_windows': {24: 150, 48: 242, 72: 314, 168: 518}}),\n",
       " ('StreamThread.java - build.gradle',\n",
       "  {'files': ['build.gradle', 'StreamThread.java'],\n",
       "   'time_windows': {24: 129, 48: 209, 72: 300, 168: 511}}),\n",
       " ('KafkaApis.scala - RequestResponseTest.java',\n",
       "  {'files': ['KafkaApis.scala', 'RequestResponseTest.java'],\n",
       "   'time_windows': {24: 369, 48: 411, 72: 433, 168: 508}})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_entries_with_largest_temporal_coupling(temporal_coupling_result, 168, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d72ce-e3c2-4004-90cb-f34cde9d9274",
   "metadata": {},
   "source": [
    "### Logical Coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d610f6-ee0d-4701-b9eb-95fce9c3c345",
   "metadata": {},
   "source": [
    "The function logical_coupling is the main function which computes the Logical-Coupling between all files in the repository.  \n",
    "Store_coupled_files_to_dict and store_file_to_dict are just helper functions to store the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a18a843-f03a-4523-bbc2-b46ef578ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_coupling(url_repo):\n",
    "\n",
    "    combination_dict = {}\n",
    "    individual_dict = {}\n",
    "\n",
    "    commits = Repository(url_repo).traverse_commits()\n",
    "    \n",
    "    for commit in tqdm(commits, desc=\"Processing Commits\", unit=\"commit\"):\n",
    "\n",
    "        modified_files = set([m.filename for m in commit.modified_files])\n",
    "\n",
    "        if len(modified_files) < 2: #no coupled files in commit\n",
    "            continue\n",
    "        \n",
    "        file_combinations = list(itertools.combinations(modified_files, 2))\n",
    "\n",
    "        for combination in file_combinations:\n",
    "\n",
    "            combination_dict = store_coupled_files_in_dict(combination_dict, combination)\n",
    "            \n",
    "        individual_dict = store_file_in_dict(individual_dict, modified_files)\n",
    "            \n",
    "        #print(\"-\"*20)\n",
    "\n",
    "    return combination_dict, individual_dict\n",
    "\n",
    "def store_coupled_files_in_dict(dictionary, combination):\n",
    "    \n",
    "    combination = sorted(combination)\n",
    "    key = combination[0] + \" - \" + combination[1]\n",
    "\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = 1\n",
    "        dictionary[key] = {\n",
    "                        \"files\": combination,\n",
    "                        \"joint_commits\": 1\n",
    "                    }\n",
    "        \n",
    "    else:\n",
    "        dictionary[key][\"joint_commits\"]+= 1\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def store_file_in_dict(dictionary, files):\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        if file not in dictionary:\n",
    "            dictionary[file] = 1\n",
    "\n",
    "        else:\n",
    "            dictionary[file]+= 1\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a81551e-df61-47de-b107-b7a1813f1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_logical_coupling_to_json(comb_dict, ind_dict, file_name):\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    # Create a tqdm progress bar for the loop\n",
    "    for key in tqdm(comb_dict, desc=\"Writing to JSON\", unit=\" pair\"):\n",
    "\n",
    "        file_pair = comb_dict[key][\"files\"]\n",
    "        joint_commits = comb_dict[key][\"joint_commits\"]\n",
    "\n",
    "        file1_commits = ind_dict[file_pair[0]] - joint_commits\n",
    "        file2_commits = ind_dict[file_pair[1]] - joint_commits\n",
    "\n",
    "        # Create a dictionary for the current pair\n",
    "        current_dict = {\n",
    "            \"file_pair\": file_pair,\n",
    "            \"logical_coupling\": {\n",
    "                \"Joint\": joint_commits,\n",
    "                file_pair[0]: file1_commits,\n",
    "                file_pair[1]: file2_commits\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the result list\n",
    "        result_list.append(current_dict)\n",
    "\n",
    "    # Save the list of dictionaries to a JSON file\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(result_list, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9d5d2-f816-40aa-b34e-9457a9f0efc0",
   "metadata": {},
   "source": [
    "Compute Logical Coupling over entire Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7723c196-4a13-4ce0-a3ab-024bc99fa99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Commits: 11903commit [02:37, 75.81commit/s]\n"
     ]
    }
   ],
   "source": [
    "comb_files_result, ind_files_result = logical_coupling(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6100a7-143c-40a4-ba8e-36911d7f353d",
   "metadata": {},
   "source": [
    "Store Logical Coupling result to JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a628b6-62a0-43b9-ae0c-7ee55e1b8b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing to JSON: 100%|█████████| 1258215/1258215 [00:03<00:00, 404415.55 pair/s]\n"
     ]
    }
   ],
   "source": [
    "store_logical_coupling_to_json(comb_files_result, ind_files_result, \"logical_coupling.JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0dd9f-55e5-4b3d-92db-7440fdf5dd37",
   "metadata": {},
   "source": [
    "Find the top 10 files which are tightest logical coupled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a675bf-f89d-4b65-87f7-7e7b5718f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_entries_with_largest_joint_commits(comb_dict, top_n=3):\n",
    "    top_entries = sorted(comb_dict.items(), key=lambda x: x[1][\"joint_commits\"], reverse=True)[:top_n]\n",
    "    \n",
    "    return top_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d93979-ad55-4241-9796-091eebd9bcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('StreamThread.java - StreamThreadTest.java',\n",
       "  {'files': ['StreamThread.java', 'StreamThreadTest.java'],\n",
       "   'joint_commits': 170}),\n",
       " ('Log.scala - LogTest.scala',\n",
       "  {'files': ['Log.scala', 'LogTest.scala'], 'joint_commits': 159}),\n",
       " ('Partition.scala - ReplicaManager.scala',\n",
       "  {'files': ['Partition.scala', 'ReplicaManager.scala'],\n",
       "   'joint_commits': 159}),\n",
       " ('KafkaApis.scala - RequestResponseTest.java',\n",
       "  {'files': ['KafkaApis.scala', 'RequestResponseTest.java'],\n",
       "   'joint_commits': 156}),\n",
       " ('KafkaApis.scala - ReplicaManager.scala',\n",
       "  {'files': ['KafkaApis.scala', 'ReplicaManager.scala'],\n",
       "   'joint_commits': 148}),\n",
       " ('KafkaApis.scala - KafkaApisTest.scala',\n",
       "  {'files': ['KafkaApis.scala', 'KafkaApisTest.scala'], 'joint_commits': 146}),\n",
       " ('ReplicaManager.scala - ReplicaManagerTest.scala',\n",
       "  {'files': ['ReplicaManager.scala', 'ReplicaManagerTest.scala'],\n",
       "   'joint_commits': 141}),\n",
       " ('StreamTask.java - StreamTaskTest.java',\n",
       "  {'files': ['StreamTask.java', 'StreamTaskTest.java'], 'joint_commits': 140}),\n",
       " ('Fetcher.java - FetcherTest.java',\n",
       "  {'files': ['Fetcher.java', 'FetcherTest.java'], 'joint_commits': 134}),\n",
       " ('AuthorizerIntegrationTest.scala - KafkaApis.scala',\n",
       "  {'files': ['AuthorizerIntegrationTest.scala', 'KafkaApis.scala'],\n",
       "   'joint_commits': 127})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_entries_with_largest_joint_commits(comb_files_result, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c06cf1-8ef0-42f0-beb3-a6f866dd5f43",
   "metadata": {},
   "source": [
    "#### In-depth analysis of 3 sets of strongly coupled files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee1c6d-4c37-4e3e-9a41-2791296e8f1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We look at 3 sets of files, which are strongly coupled by **logical coupling**:\n",
    "\n",
    "##### 1. `StreamThread.java` and `StreamThreadTest.java`\n",
    "\n",
    "With 170 joint commits StreamThread.java and StreamThreadTest.java are strongest coupled files from the whole Kafka repository.\n",
    "It is reasonable that when modifications in the class of StreamThread.java are made, that also the tests need to adjusted accordingly in the StreamThreadTest.java . It makes sense, that there is always a coupling between a file and it's corresponding test-file, they go often hand-in-hand. --> Unit-Test-Relationship\n",
    "\n",
    "##### 2. `Partition.scala`and `ReplicaManager.scala`\n",
    "\n",
    "Tese two files have 159 joint commits and also strongly logical coupled.  \n",
    "The files have an architectural dependency. Meaning that ReplicaManager is responsible for managing the state of partitions. \n",
    "To manage the states of partitions, ReplicaManager.scala is dependend on Partition.scala, which means modifications in Partition.scala often lead to modifications in ReplicaManager.scala.\n",
    "\n",
    "##### 3. `KafkaApis.scala`and `ReplicaManager.scala`\n",
    "\n",
    "These two filese have 148 joint commits. These files have also an architectural dependency.  \n",
    "Meaning KafkaApi.scala seem to strongly depend on ReplicaManager.scala, resulting that modifications in ReplicaManager.scale enforce also changes in KafkaApis.scala."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
